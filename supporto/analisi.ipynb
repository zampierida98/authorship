{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODULO SALVATAGGIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import math\n",
    "import pickle\n",
    "import statistics\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# %% Attributi sull'intero testo\n",
    "def word_counter(RDD):\n",
    "    '''\n",
    "    Data una RDD, conta quante volte compare ogni parola ritornando anche la dimensione del vocabolario.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD : RDD\n",
    "        RDD del file in input\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (RDD, int)\n",
    "        RDD dell'output del word count e dimensione del vocabolario\n",
    "    '''\n",
    "    \n",
    "    word_counter = (RDD.flatMap(lambda x: x)\n",
    "                    .map(lambda x: (x,1))\n",
    "                    .reduceByKey(lambda a,b: a+b)\n",
    "                    .sortBy(lambda x: -x[1])\n",
    "                   )\n",
    "    \n",
    "    return word_counter, word_counter.count()\n",
    "\n",
    "def text_length_in_words(RDD_word_counter):\n",
    "    '''\n",
    "    Calcola la lunghezza del testo in termini di numero di parole.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_word_counter : RDD\n",
    "        RDD dell'output del word count\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        numero di parole totali presenti nel testo\n",
    "    '''\n",
    "\n",
    "    return (RDD_word_counter.map(lambda x: x[1])\n",
    "            .reduce(lambda a,b: a+b)\n",
    "           )\n",
    "\n",
    "def entropy(RDD_word_counter, text_len):\n",
    "    '''\n",
    "    Calcola l'entropia (numero medio di bit richiesti per rappresentare tutte le parole del testo).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_word_counter : RDD\n",
    "        RDD dell'output del word count\n",
    "    text_len : int\n",
    "        numero di parole totali presenti nel testo\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        valore dell'entropia\n",
    "    '''\n",
    "    \n",
    "    return -(RDD_word_counter.map(lambda x: (x[1]/text_len) * math.log2(x[1]/text_len))\n",
    "             .reduce(lambda a,b: a+b)\n",
    "            ) # l'entropia ha segno negativo\n",
    "\n",
    "# %% Attributi sulle frasi\n",
    "def sentence_lengths(RDD):\n",
    "    '''\n",
    "    Calcola le lunghezze (in termini di numero di parole) di tutte le frasi di un testo.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD : RDD\n",
    "        RDD del file in input\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    RDD\n",
    "        RDD che contiene le lunghezze delle frasi\n",
    "    '''\n",
    "    \n",
    "    # operazioni preliminari sul testo\n",
    "    text = RDD.flatMap(lambda x: x).reduce(lambda a,b: a + ' ' + b) # metto tutto il testo in una stringa unica\n",
    "    text = text.replace(\"?\", \".\") # ? termina una frase\n",
    "    text = text.replace(\"!\", \".\") # ! termina una frase\n",
    "    text = text.split('. ') # splitto quando trovo un carattere che termina una frase (. seguito da uno spazio)\n",
    "    \n",
    "    return (sc.parallelize(text)\n",
    "            .map(lambda x: len(x.split(' ')))\n",
    "           ) # per ogni frase trovata conto le sue parole\n",
    "\n",
    "def prob_distr_of_sentence_length(RDD_sen_len):\n",
    "    '''\n",
    "    Ritorna una lista che contiene la distribuzione di probabilità delle lunghezze delle frasi.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_sen_len : RDD\n",
    "        RDD dell'output di sentence_lengths\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        distribuzione di probabilità delle lunghezze delle frasi\n",
    "    '''\n",
    "    \n",
    "    tot = RDD_sen_len.count()\n",
    "\n",
    "    return (RDD_sen_len.map(lambda x: (x,1))\n",
    "            .reduceByKey(lambda a,b: a+b)\n",
    "            .map(lambda x: (x[0], x[1]/tot))\n",
    "            .sortBy(lambda x: -x[1])\n",
    "           )\n",
    "\n",
    "# %% Attributi sulla probabilità delle parole\n",
    "def prob_distr_of_most_common_words(RDD_word_counter, text_len):\n",
    "    '''\n",
    "    Ritorna la distribuzione di probabilità delle parole più comuni.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_word_counter : RDD\n",
    "        RDD dell'output del word count\n",
    "    text_len : int\n",
    "        numero di parole totali presenti nel testo\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    RDD\n",
    "        RDD che contiene la distribuzione di probabilità\n",
    "    '''\n",
    "    \n",
    "    return RDD_word_counter.map(lambda x: (x[0], x[1]/text_len))\n",
    "\n",
    "def prob_of_the_most_common_word(RDD_prob_distr_of_MCWs):\n",
    "    '''\n",
    "    Ritorna la probabilità della parola più comune (escludendo 'and' e 'the').\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_prob_distr_of_MCWs : RDD\n",
    "        RDD con la distribuzione di probabilità\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        MCW e relativa probabilità\n",
    "    '''\n",
    "    \n",
    "    return (RDD_prob_distr_of_MCWs\n",
    "            .filter(lambda x: x[0] != \"and\" and x[0] != \"the\")\n",
    "            .take(1)\n",
    "           )[0]\n",
    "\n",
    "def prob_of_the_most_common_word_x(RDD_prob_distr_of_MCWs):\n",
    "    '''\n",
    "    Ritorna la probabilità della parola più comune (escludendo articoli e preposizioni).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_prob_distr_of_MCWs : RDD\n",
    "        RDD con la distribuzione di probabilità\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        MCWx e relativa probabilità\n",
    "    '''\n",
    "    \n",
    "    prep_art = open(\"preposizioni_e_articoli.txt\").read().splitlines()\n",
    "    \n",
    "    return (RDD_prob_distr_of_MCWs\n",
    "            .filter(lambda x: x[0] not in prep_art)\n",
    "            .take(1)\n",
    "           )[0]\n",
    "\n",
    "def prob_of_The(RDD_prob_distr_of_MCWs):\n",
    "    '''\n",
    "    Ritorna la probabilità della parola \"the\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_prob_distr_of_MCWs : RDD\n",
    "        RDD con la distribuzione di probabilità\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    RDD\n",
    "        RDD che contiene la probabilità della parola \"the\"\n",
    "    '''\n",
    "    \n",
    "    return (RDD_prob_distr_of_MCWs\n",
    "            .filter(lambda x: x[0] == \"the\")\n",
    "           )\n",
    "\n",
    "def prob_of_comma(RDD_sentences_data, text_len):\n",
    "    '''\n",
    "    Ritorna la probabilità di presenza della virgola.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_sentences_data : RDD\n",
    "        RDD del file in input\n",
    "    text_len : int\n",
    "        numero di parole totali presenti nel testo\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        probabilità di presenza della virgola\n",
    "    '''\n",
    "    \n",
    "    return (RDD_sentences_data\n",
    "            .flatMap(lambda x: x)\n",
    "            .filter(lambda x: \",\" in x)\n",
    "            .count()\n",
    "           ) / text_len\n",
    "\n",
    "# %% Attributi sulla distanza\n",
    "def distance_consec_appear(RDD, word):\n",
    "    '''\n",
    "    Ritorna una lista che contiene le distanze tra apparenze consecutive di word.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD : RDD\n",
    "        RDD del file in input\n",
    "    word : str\n",
    "        parola da trattare\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        distanze tra apparenze consecutive di word\n",
    "    '''\n",
    "    \n",
    "    if word == ',':\n",
    "        vect_pos = (RDD.flatMap(lambda x:x)\n",
    "                    .zipWithIndex()\n",
    "                    .filter(lambda x: ',' in x[0])\n",
    "                    .map(lambda x: x[1])\n",
    "                    .collect()\n",
    "                   )\n",
    "    else:\n",
    "        vect_pos = (RDD.flatMap(lambda x:x)\n",
    "                    .zipWithIndex()\n",
    "                    .filter(lambda x: x[0] == word)\n",
    "                    .map(lambda x: x[1])\n",
    "                    .collect()\n",
    "                   )\n",
    "    \n",
    "    vect_dis = []\n",
    "    \n",
    "    for i in range(1, len(vect_pos)):\n",
    "        vect_dis.append(vect_pos[i] - vect_pos[i-1])\n",
    "    \n",
    "    return vect_dis\n",
    "\n",
    "# %% Funzioni di supporto\n",
    "def remove_number_some_punctuation_marks(row):\n",
    "    '''\n",
    "    Rimuove i caratteri numerici e i caratteri \" e -- dalla stringa e la trasforma in lower-case.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    row : str\n",
    "        riga del file in input\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    res : str\n",
    "        riga senza --, \", e i numeri\n",
    "    '''\n",
    "    \n",
    "    lowercase = row.lower()\n",
    "    lowercase = lowercase.replace(\"--\", \" \")\n",
    "    \n",
    "    res = \"\"\n",
    "    \n",
    "    for char in lowercase:\n",
    "        if not ('0' <= char <= '9' or char == '\"'):\n",
    "            res += char\n",
    "\n",
    "    return res\n",
    "\n",
    "def remove_number_punctuation_marks(row):\n",
    "    '''\n",
    "    Rimuove i caratteri numerici e i segni di punteggiatura dalla stringa e la trasforma in lower-case.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    row : str\n",
    "        riga del file in input\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    res : str\n",
    "        riga senza numeri e segni di punteggiatura\n",
    "    '''\n",
    "    \n",
    "    lowercase = row.lower()\n",
    "    lowercase = lowercase.replace(\"--\", \" \")\n",
    "    \n",
    "    res = \"\"\n",
    "    \n",
    "    for char in lowercase:\n",
    "        if 'a' <= char <= 'z' or char == ' ' or char == '-' or char == \"'\":\n",
    "            res += char\n",
    "\n",
    "    return res\n",
    "\n",
    "def load_file_without_punctuations_marks(filepath):\n",
    "    '''\n",
    "    Carica il contenuto di un file in una RDD (tralasciando numeri e segni di punteggiatura).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        path del file da caricare\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    RDD\n",
    "        RDD del contenuto del file\n",
    "    '''\n",
    "    \n",
    "    # caricamento del dataset\n",
    "    raw_text = sc.textFile(filepath)\n",
    "\n",
    "    # rimuoviamo i numeri e i segni di punteggiatura\n",
    "    \n",
    "    return (raw_text.filter(bool)                    # rimuoviamo le stringhe vuote\n",
    "        .map(remove_number_punctuation_marks)\n",
    "        .map(lambda x : ' '.join(x.split()))        # rimuoviamo diversi spazi bianchi con uno\n",
    "        .map(lambda row : row.split(\" \"))\n",
    "       )\n",
    "\n",
    "def load_file_without_number(filepath):\n",
    "    '''\n",
    "    Carica il contenuto di un file in una RDD (tralasciando i numeri e i caratteri \" e --).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        path del file da caricare\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    RDD\n",
    "        RDD del contenuto del file\n",
    "    '''\n",
    "    \n",
    "    # caricamento del dataset\n",
    "    raw_text = sc.textFile(filepath)\n",
    "\n",
    "    # rimuoviamo i numeri e i segni di punteggiatura\n",
    "    \n",
    "    return (raw_text.filter(bool)                    # rimuoviamo le stringhe vuote\n",
    "        .map(remove_number_some_punctuation_marks)\n",
    "        .map(lambda x : ' '.join(x.split()))        # rimuoviamo diversi spazi bianchi con uno\n",
    "        .map(lambda row : row.split(\" \"))\n",
    "       )\n",
    "\n",
    "def getCollection(RDD):\n",
    "    return RDD.collect()\n",
    "\n",
    "def getValue(RDD):\n",
    "    return RDD.collect()[0]\n",
    "\n",
    "def mean_std_couple(_list, tot_el):\n",
    "    for i in range(0, tot_el - len(_list)):\n",
    "        _list.append(0)\n",
    "\n",
    "    return (statistics.mean(_list), statistics.stdev(_list))\n",
    "\n",
    "# %% Salvataggio degli attributi\n",
    "def generate_metrics(file_in):\n",
    "    '''\n",
    "    Ritorna un dizionario contenente tutti gli attributi estratti da un testo.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_in : str\n",
    "        path del file da analizzare\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        dizionario degli attributi estratti\n",
    "    '''\n",
    "    \n",
    "    res = {}\n",
    "    \n",
    "    # consideriamo il testo SENZA i segni di punteggiatura\n",
    "    print(\"Caricamento del file in memoria ...\", end=\" \")\n",
    "    data = load_file_without_punctuations_marks(file_in)\n",
    "    data.persist()\n",
    "    print(\"caricamento completato\")\n",
    "\n",
    "    # calcoliamo le prime metriche\n",
    "    print(\"Calcolo delle prime metriche, attendere ...\", end=\" \")\n",
    "    \n",
    "    RDD_word_counter, vocabulary_size = word_counter(data)\n",
    "    RDD_word_counter.persist()\n",
    "    text_length = text_length_in_words(RDD_word_counter)\n",
    "    entropy_value = entropy(RDD_word_counter, text_length)\n",
    "    \n",
    "    RDD_prob_distr_of_MCWs = prob_distr_of_most_common_words(RDD_word_counter, text_length)\n",
    "    prob_the_most_common_word = prob_of_the_most_common_word(RDD_prob_distr_of_MCWs)\n",
    "    prob_the_most_common_word_x = prob_of_the_most_common_word_x(RDD_prob_distr_of_MCWs)\n",
    "    prob_the = prob_of_The(RDD_prob_distr_of_MCWs)\n",
    "\n",
    "    MCW = prob_the_most_common_word[0]\n",
    "    dist_consec_MCW = distance_consec_appear(data, MCW)\n",
    "    \n",
    "    MCWx = prob_the_most_common_word_x[0]\n",
    "    dist_consec_MCWx = distance_consec_appear(data, MCWx)\n",
    "    \n",
    "    dist_consec_the = distance_consec_appear(data, 'the')\n",
    "        \n",
    "    print(\"calcolo completato\")\n",
    "\n",
    "    \n",
    "    # consideriamo il testo CON i segni di punteggiatura\n",
    "    print(\"Caricamento del file in memoria ...\", end=\" \")\n",
    "    sentences_data = load_file_without_number(file_in)\n",
    "    sentences_data.persist()\n",
    "    print(\"caricamento completato\")\n",
    "    \n",
    "    # calcoliamo altre metriche\n",
    "    print(\"Calcolo di ulteriori metriche, attendere ...\", end=\" \")\n",
    "    \n",
    "    RDD_sen_lengths = sentence_lengths(sentences_data)\n",
    "    RDD_sen_lengths.persist()\n",
    "\n",
    "    sen_lengths = RDD_sen_lengths.collect()\n",
    "\n",
    "    prob_distr_freq_sen = prob_distr_of_sentence_length(RDD_sen_lengths)\n",
    "    \n",
    "    p_comma = prob_of_comma(sentences_data, text_length)\n",
    "\n",
    "    dist_consec_comma = distance_consec_appear(sentences_data, ',')\n",
    "    \n",
    "    print(\"calcolo completato\")\n",
    "    \n",
    "    \n",
    "    # popoliamo il dizionario\n",
    "    \n",
    "    # attributi sull'intero testo\n",
    "    res['vocabulary_size'] = vocabulary_size\n",
    "    res['text_length'] = text_length\n",
    "    res['V_T'] = vocabulary_size/text_length\n",
    "    res['entropy'] = entropy_value\n",
    "    \n",
    "    # attributi sulle frasi\n",
    "    res['avg_sentence_len'] = sum(sen_lengths)/len(sen_lengths)\n",
    "    res['max_sentence_len'] = max(sen_lengths)\n",
    "    res['min_sentence_len'] = min(sen_lengths)\n",
    "    res['prob_distr_freq_sen'] = getCollection(prob_distr_freq_sen)\n",
    "    res['prob_most_freq_sen'] = getValue(prob_distr_freq_sen)[1]\n",
    "    \n",
    "    # attributi sulla probabilità delle parole\n",
    "    res['prob_distr_of_30'] = RDD_prob_distr_of_MCWs.take(30)\n",
    "    res['prob_of_the_most_common_word'] = prob_the_most_common_word[1]\n",
    "    res['prob_of_the_most_common_word_x'] = prob_the_most_common_word_x[1]\n",
    "    res['prob_of_the'] = getValue(prob_the)[1]\n",
    "    res['prob_of_comma'] = p_comma\n",
    "    \n",
    "    # attributi sulla distanza\n",
    "    res['avg_dist_consec_comma'] = sum(dist_consec_comma)/len(dist_consec_comma)\n",
    "    res['min_dist_consec_comma'] = min(dist_consec_comma)\n",
    "    res['max_dist_consec_comma'] = max(dist_consec_comma)\n",
    "    \n",
    "    res['avg_dist_consec_MCW'] = sum(dist_consec_MCW)/len(dist_consec_MCW)\n",
    "    res['min_dist_consec_MCW'] = min(dist_consec_MCW)\n",
    "    res['max_dist_consec_MCW'] = max(dist_consec_MCW)\n",
    "    \n",
    "    res['avg_dist_consec_MCWx'] = sum(dist_consec_MCWx)/len(dist_consec_MCWx)\n",
    "    res['min_dist_consec_MCWx'] = min(dist_consec_MCWx)\n",
    "    res['max_dist_consec_MCWx'] = max(dist_consec_MCWx)\n",
    "    \n",
    "    res['avg_dist_consec_the'] = sum(dist_consec_the)/len(dist_consec_the)\n",
    "    res['min_dist_consec_the'] = min(dist_consec_the)\n",
    "    res['max_dist_consec_the'] = max(dist_consec_the)\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def save_metrics(file_in, file_out):\n",
    "    '''\n",
    "    Salva un dizionario in un file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_in : str\n",
    "        path del file da analizzare\n",
    "    file_out: str\n",
    "        path del file in cui salvare la entry\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "\n",
    "    entry = generate_metrics(file_in)\n",
    "    \n",
    "    with open(file_out, 'ab') as fout:\n",
    "        pickle.dump(entry, fout, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print(\"Salvataggio completato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODULO ANALISI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_std_couple(_list, tot_el):\n",
    "    for i in range(0, tot_el - len(_list)):\n",
    "        _list.append(0)\n",
    "\n",
    "    return (statistics.mean(_list), statistics.stdev(_list))\n",
    "\n",
    "def load_metrics(file_in):\n",
    "    '''\n",
    "    Carica i dizionari degli attributi presenti in un file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_in : str\n",
    "        path del file da cui caricare\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        lista di dizionari degli attributi\n",
    "    '''\n",
    "\n",
    "    res = []\n",
    "    \n",
    "    with open(file_in, \"rb\") as fin:\n",
    "        while True:\n",
    "            try:\n",
    "                res.append(pickle.load(fin))\n",
    "            except EOFError:\n",
    "                break\n",
    "                \n",
    "    return res\n",
    "\n",
    "def author_metrics(author_name):\n",
    "    '''\n",
    "    Calcola media e deviazione standard degli attributi (provenienti da vari testi) di un autore.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    author_name : str\n",
    "        nome del file contenente i dizionari degli attributi\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        dizionario con media e deviazione standard degli attributi\n",
    "    '''\n",
    "    \n",
    "    analisi = load_metrics(author_name)\n",
    "    res = {}\n",
    "    \n",
    "    # recupero gli attributi dai dizionari e li metto sotto la stessa chiave\n",
    "    for diz in analisi:\n",
    "        for key in diz:\n",
    "            try:\n",
    "                res[key] += [diz[key]]\n",
    "            except:\n",
    "                res[key] = [diz[key]]\n",
    "    \n",
    "    for key in res:\n",
    "        if type(res[key][0]) != list:\n",
    "            # se l'attributo NON è una lista, calcolo direttamente media e deviazione standard\n",
    "            res[key] = (statistics.mean(res[key]), statistics.stdev(res[key]))\n",
    "        else:\n",
    "            # se l'attributo è una lista, calcolo direttamente media e deviazione standard\n",
    "            tot_el = len(res[key])\n",
    "            res[key] = (sc.parallelize(res[key])\n",
    "                        .flatMap(lambda x: x)\n",
    "                        .map(lambda x: (x[0], [x[1]]))\n",
    "                        .reduceByKey(lambda a,b: a+b)\n",
    "                        .map(lambda x: (x[0], mean_std_couple(x[1], tot_el)))\n",
    "                        .collect()\n",
    "                       )\n",
    "    \n",
    "    return res\n",
    "\n",
    "def save_metrics(file_in, file_out):\n",
    "    '''\n",
    "    Salva un dizionario in un file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_in : str\n",
    "        path del file da analizzare\n",
    "    file_out: str\n",
    "        path del file in cui salvare la entry\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "\n",
    "    entry = author_metrics(file_in)\n",
    "    \n",
    "    with open(file_out, 'ab') as fout:\n",
    "        pickle.dump(entry, fout, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print(\"Salvataggio completato\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caricamento autori noti e file da analizzare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd = load_metrics(\"Charles Dickens\")[0]\n",
    "dd = load_metrics(\"Daniel Defoe\")[0]\n",
    "jl = load_metrics(\"Jack London\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary_size --> (17676.8, 1661.7033964512975) \n",
      "\n",
      "text_length --> (310102.1, 50914.59551368568) \n",
      "\n",
      "V_T --> (0.05806833691456287, 0.008477437055675502) \n",
      "\n",
      "entropy --> (9.748569557579543, 0.1536023391440371) \n",
      "\n",
      "avg_sentence_len --> (22.78072322856244, 4.466290808954688) \n",
      "\n",
      "max_sentence_len --> (266.1, 77.90799416976127) \n",
      "\n",
      "min_sentence_len --> (1, 0.0) \n",
      "\n",
      "prob_distr_freq_sen --> [(8, (0.03271635328827866, 0.0052201618147841924)), (16, (0.022343906509243196, 0.001976848061578728)), (24, (0.016730775512647015, 0.0020992696657855013)), (32, (0.012191841931870017, 0.0024993075247798234)), (40, (0.00838450768029358, 0.0021259793700965385)), (48, (0.005850901430041335, 0.001967647326376615)), (56, (0.0035769944670158895, 0.0013856247103392933)), (64, (0.002365475582668507, 0.0010856579011425946)), (72, (0.0017016958419777378, 0.0006687944837405318)), (88, (0.0007920271755496543, 0.0005075005453611686)), (80, (0.0009748879564512182, 0.0004800554029103804)), (112, (0.00024064730479252417, 0.00021827660819326422)), (96, (0.00051224582242304, 0.00030946978608956696)), (104, (0.00040992668492506005, 0.0003797399583006165)), (144, (3.75511382113374e-05, 5.396133097416207e-05)), (128, (0.00011248386828189323, 9.910016610266679e-05)), (160, (3.560750905581898e-05, 4.9639728326640904e-05)), (120, (0.00016227970753573989, 0.0002537113102323826)), (152, (5.8411045292090804e-05, 9.728454065579094e-05)), (136, (7.522736598849231e-05, 8.132619450494394e-05)), (184, (3.394494475395672e-05, 6.461713139434809e-05)), (168, (2.1665696586678147e-05, 3.489085885558545e-05)), (176, (2.4294287343122784e-05, 3.97905313929725e-05)), (216, (7.247952453431905e-06, 2.292003812545031e-05)), (200, (7.247952453431905e-06, 2.292003812545031e-05)), (9, (0.03091435188861385, 0.003804033139286029)), (17, (0.02188652709458143, 0.0020689437786545776)), (1, (0.04210867798626682, 0.02845910738837436)), (25, (0.015516747401989188, 0.0019237495645144061)), (33, (0.011201793719196612, 0.002203856545666042)), (41, (0.008337340278161213, 0.0021004281793017463)), (49, (0.005470697817884247, 0.0017514606601113903)), (57, (0.0034150251054556307, 0.0010819449134838127)), (73, (0.001771316697899039, 0.0007869101446414948)), (65, (0.0023059448805319077, 0.0012022857795918954)), (81, (0.0008763480257930027, 0.0004259864165772325)), (89, (0.0007174055092919369, 0.0004676703142346315)), (105, (0.00034589723260621284, 0.0002482028779159167)), (121, (0.00018340938310765022, 0.00018081114245420044)), (97, (0.0003876242460563665, 0.00027534486993765074)), (113, (0.00025386823876088826, 0.00018238541462775872)), (169, (2.8218907680442496e-05, 6.771534397204872e-05)), (137, (6.505029810019323e-05, 7.385426269729807e-05)), (201, (1.77334300669372e-05, 3.815619963556746e-05)), (233, (1.593655420113135e-05, 3.563115066076716e-05)), (217, (1.0485477613505295e-05, 3.315799161338345e-05)), (145, (6.724524996082931e-05, 9.450997395494355e-05)), (129, (7.822351370174693e-05, 8.743899894473837e-05)), (153, (3.980656759377718e-05, 4.806833185922732e-05)), (185, (2.4294287343122784e-05, 3.97905313929725e-05)), (161, (1.672679666925454e-05, 3.597738572937484e-05)), (241, (7.247952453431905e-06, 2.292003812545031e-05)), (177, (3.0062780046799195e-05, 5.0232907421068315e-05)), (209, (1.2938284383490749e-05, 4.091444766681821e-05)), (193, (1.2938284383490749e-05, 4.091444766681821e-05)), (10, (0.030407348591952592, 0.0028797087555271733)), (2, (0.02780713518122091, 0.013668103992369776)), (18, (0.02124658753189237, 0.0017913805609874479)), (26, (0.015694079047031916, 0.0027863816223413318)), (34, (0.011010886354196012, 0.0024123661338974183)), (42, (0.007272061569766622, 0.0016143854275618647)), (50, (0.005108650456863767, 0.0015418250991284393)), (58, (0.0033131943798400533, 0.0013450195490508068)), (74, (0.0015589118594951633, 0.0008068258655043143)), (66, (0.002187048876560737, 0.000932553398139758)), (82, (0.000827152333021309, 0.0004572046546286877)), (90, (0.0007124752629930378, 0.00044549551750229114)), (98, (0.00039257902728876646, 0.0003078753436470601)), (106, (0.0002719639288722252, 0.00017444948433538557)), (122, (0.00015354756552723162, 0.00015833005385090947)), (130, (7.545784443931377e-05, 0.00010524834648896475)), (146, (4.463817546422797e-05, 6.554512666424438e-05)), (114, (0.00020437464365386657, 0.00011487759398641364)), (170, (2.3423761996996042e-05, 4.971889658226422e-05)), (162, (3.406252774213783e-05, 5.5694569531046245e-05)), (210, (1.0485477613505295e-05, 3.315799161338345e-05)), (186, (1.733573107288329e-05, 3.753790026358661e-05)), (258, (1.0485477613505295e-05, 3.315799161338345e-05)), (154, (2.225899405805737e-05, 3.734687321960199e-05)), (194, (2.0186236836922652e-05, 4.461982640930136e-05)), (466, (7.247952453431905e-06, 2.292003812545031e-05)), (178, (1.5408740598679377e-05, 3.406014044492091e-05)), (138, (1.5408740598679377e-05, 3.406014044492091e-05)), (218, (1.2938284383490749e-05, 4.091444766681821e-05)), (3, (0.03309243820746789, 0.011854402097951433)), (11, (0.027769502806849037, 0.001889673045638067)), (19, (0.020199391561059234, 0.002366646300158476)), (27, (0.014504842782694143, 0.0019901180282796294)), (35, (0.010501819292638537, 0.002259302672320309)), (43, (0.0070602724380523394, 0.0018138716121930344)), (51, (0.004856362072280488, 0.0015570734819106483)), (59, (0.002638711021627487, 0.0009718882076282738)), (67, (0.0019933093438348794, 0.0009113116499105217)), (75, (0.0014038284826865075, 0.0006674612560728963)), (83, (0.0008138569700076752, 0.0003839909037797917)), (91, (0.0006410155589451695, 0.00032863497110093834)), (99, (0.0005703743718266116, 0.0005223997394312418)), (107, (0.0002520851642622542, 0.00019283331789903801)), (115, (0.0002236432262500618, 0.00019302535671469952)), (147, (5.6125923322869885e-05, 5.30730691431472e-05)), (203, (1.0485477613505295e-05, 3.315799161338345e-05)), (123, (8.473552579031977e-05, 7.977015654882894e-05)), (139, (4.476992036323785e-05, 6.0915889020562505e-05)), (131, (7.447882210698236e-05, 7.522403531557456e-05)), (163, (4.60381447034185e-05, 7.16752917949941e-05)), (171, (3.154223979655469e-05, 4.144052503261043e-05)), (155, (6.850253459377997e-06, 2.1662403481082197e-05)), (227, (7.076139258420605e-06, 2.2376717097143924e-05)), (267, (7.076139258420605e-06, 2.2376717097143924e-05)), (187, (1.9753086419753087e-05, 6.246474390456057e-05)), (283, (9.876543209876543e-06, 3.1232371952280284e-05)), (235, (9.876543209876543e-06, 3.1232371952280284e-05)), (179, (1.2938284383490749e-05, 4.091444766681821e-05)), (4, (0.038130440810405467, 0.010554694540193674)), (12, (0.02661219958573323, 0.002962363446807717)), (20, (0.01886244441298239, 0.001631157967453343)), (28, (0.014410434263898169, 0.002285900504690595)), (36, (0.010009358363478828, 0.0023098705216727756)), (44, (0.006851151591119326, 0.0020342804457814416)), (52, (0.004538783196038897, 0.0016406961462732959)), (60, (0.0031010222225837736, 0.0015695938168540724)), (68, (0.0021946166189290976, 0.0009698614151545136)), (76, (0.0012871227587635732, 0.0006416192844592357)), (84, (0.0008669277797832397, 0.00048355655792529435)), (124, (0.00014089722461695456, 0.000161800925341232)), (100, (0.0003886074568831731, 0.000368199513210691)), (92, (0.0005304681390326425, 0.00030333734698026406)), (108, (0.0002081628418499513, 0.00021140635587435817)), (116, (0.0001943137330438197, 0.00016888059885025825)), (180, (2.8047094485431195e-05, 6.759263265494528e-05)), (148, (5.665958508400635e-05, 7.212641553361452e-05)), (164, (3.390923961050134e-05, 7.395167437253452e-05)), (140, (0.00013808129784880397, 0.00020650326138201282)), (132, (6.753279745695982e-05, 5.411842445076998e-05)), (260, (1.0485477613505295e-05, 3.315799161338345e-05)), (156, (1.721814808470218e-05, 3.678749871717424e-05)), (196, (6.850253459377997e-06, 2.1662403481082197e-05)), (188, (1.9788537842868747e-05, 4.411683380524138e-05)), (228, (1.9788537842868747e-05, 4.411683380524138e-05)), (172, (2.9665081052745287e-05, 4.987423935769341e-05)), (244, (7.247952453431905e-06, 2.292003812545031e-05)), (204, (7.247952453431905e-06, 2.292003812545031e-05)), (5, (0.03907065713818872, 0.00855708079063729)), (13, (0.025061418794483453, 0.002048296666613009)), (21, (0.01917423477140546, 0.002062831877988008)), (29, (0.013315094837678258, 0.0018704422692983214)), (37, (0.009640351191512204, 0.002217665693715739)), (45, (0.006452118407887209, 0.002146940754095201)), (53, (0.004700005710248473, 0.0016190893622492727)), (61, (0.0025723311603465674, 0.0009657496076565625)), (69, (0.0017849905215880548, 0.0007853679901204306)), (93, (0.0007691085890563925, 0.000508636825554039)), (85, (0.0009196159350123073, 0.00042362511957863607)), (77, (0.0011525149160387868, 0.0005912274746196973)), (109, (0.00024357293070384746, 0.00022848171261402497)), (101, (0.00043306717143097985, 0.0002687040880071981)), (149, (8.590318186038371e-05, 9.970601911561142e-05)), (117, (0.00017717612283874067, 0.00017409415740418405)), (157, (7.252761866547663e-05, 7.344080676851715e-05)), (133, (8.9013245936361e-05, 0.00015612097267739933)), (245, (1.0485477613505295e-05, 3.315799161338345e-05)), (253, (1.0485477613505295e-05, 3.315799161338345e-05)), (125, (0.00012495383060676644, 0.00016459258545980962)), (141, (2.9254012515301202e-05, 3.925392212229173e-05)), (197, (6.850253459377997e-06, 2.1662403481082197e-05)), (165, (6.850253459377997e-06, 2.1662403481082197e-05)), (205, (7.247952453431905e-06, 2.292003812545031e-05)), (173, (3.8223568192046666e-05, 7.008603580281303e-05)), (6, (0.037114662230236316, 0.006741232793104839)), (14, (0.024544756442535627, 0.0021348662750583793)), (22, (0.017366828691464553, 0.0022970741409763847)), (30, (0.012991810894496159, 0.002558295554683467)), (38, (0.009005965310668601, 0.0025480126139325156)), (46, (0.006493622531230506, 0.0016406016162859188)), (54, (0.003899445524775418, 0.001225825356089073)), (62, (0.002812910378479834, 0.0012477092245225662)), (70, (0.0017416448666567027, 0.0008329646572842049)), (78, (0.0012691719916040197, 0.0005336012126773803)), (86, (0.0008872220798302513, 0.00047127315664520497)), (102, (0.00037577884726588306, 0.00028954200424588354)), (94, (0.0005385976664893733, 0.0002597284085140353)), (126, (7.775641556305717e-05, 7.963567657738074e-05)), (118, (0.0001384946963758678, 0.00011066584097464193)), (166, (3.027401545637404e-05, 5.083948758853628e-05)), (198, (1.782708248833093e-05, 3.8306355132276636e-05)), (174, (2.0362020823381836e-05, 4.295089668688803e-05)), (142, (6.284270314147753e-05, 8.53400668352226e-05)), (190, (1.733573107288329e-05, 3.753790026358661e-05)), (110, (0.00019660962408488643, 0.00018812234980423979)), (150, (8.199170156722137e-05, 0.00016687496969321455)), (206, (1.1365890190213325e-05, 2.50714268506821e-05)), (158, (7.341604874825637e-06, 2.321619308544438e-05)), (134, (4.738413081240363e-05, 5.6527377188552794e-05)), (214, (1.9753086419753087e-05, 6.246474390456057e-05)), (318, (9.876543209876543e-06, 3.1232371952280284e-05)), (230, (9.876543209876543e-06, 3.1232371952280284e-05)), (238, (1.2938284383490749e-05, 4.091444766681821e-05)), (246, (5.532197388802833e-06, 1.749434421425304e-05)), (7, (0.035415060337055854, 0.006381508614617202)), (15, (0.023699411432408477, 0.002018980496895898)), (23, (0.01693817489294075, 0.0018582708271579242)), (31, (0.012457790898067644, 0.00222331490720369)), (39, (0.008668274987195457, 0.002352470498026311)), (47, (0.005741015848252515, 0.0016677015231202521)), (55, (0.0038814067964929046, 0.001325501899989885)), (63, (0.0026031113366702715, 0.0010936397796130629)), (71, (0.0017584610721418034, 0.000876516356853875)), (79, (0.0011236376628137998, 0.0005591334486907686)), (87, (0.0008673840716498835, 0.0005730427949806163)), (95, (0.0003104716547564991, 0.0001992708924762366)), (143, (0.00012801916667261998, 0.00015006661629459904)), (119, (0.0001767275108246484, 0.00014886283576939167)), (111, (0.00019423606074884113, 0.00011415657603066466)), (127, (0.00010039185306096819, 0.00011040199937724809)), (135, (2.7609973276813743e-05, 4.519010448371927e-05)), (103, (0.00030442305642170526, 0.00024659881552617236)), (175, (5.228324923643871e-05, 9.287755922454083e-05)), (183, (2.175934900807188e-05, 4.925235114876443e-05)), (167, (2.0279889258316384e-05, 4.474259393627639e-05)), (151, (2.9904645505543186e-05, 5.2583667776311306e-05)), (255, (7.247952453431905e-06, 2.292003812545031e-05)), (215, (7.076139258420605e-06, 2.2376717097143924e-05)), (159, (1.695268246829715e-05, 3.6343807098020125e-05)), (239, (1.2938284383490749e-05, 4.091444766681821e-05))] \n",
      "\n",
      "prob_most_freq_sen --> (0.05041899684343097, 0.02189549719246276) \n",
      "\n",
      "prob_distr_of_30 --> [('of', (0.02636860922752125, 0.0029956829049676316)), ('he', (0.012363455462818685, 0.0017244609349436775)), ('i', (0.014453978951076892, 0.00903439582606544)), ('but', (0.004673968922929178, 0.0017288483982598206)), ('are', (0.0003928650635237461, 0.0012423484138417737)), ('a', (0.022181049167960126, 0.0017275203751073568)), ('that', (0.012436742664761413, 0.0017300098557359277)), ('you', (0.00961968726902842, 0.0024630772972828174)), ('by', (0.001886488728437715, 0.002439400101370885)), ('which', (0.0020651650703328345, 0.0026829485008902764)), ('who', (0.00039524126350473654, 0.001249862617957752)), ('pickwick', (0.000690629726932569, 0.0021839629569270513)), ('as', (0.008547048180988661, 0.0006267767714848956)), ('at', (0.006966841683453419, 0.0001892770258002784)), ('said', (0.005968522030146302, 0.003479127018423429)), ('this', (0.001451534566082143, 0.002340674200351409)), ('we', (0.000486724962772867, 0.0015391594764229235)), ('it', (0.011350991351185395, 0.002233228360820954)), ('for', (0.006947836463339511, 0.0005303888050444346)), ('my', (0.004340889062020483, 0.004809604294272696)), ('so', (0.001478556551704967, 0.0023992890646514285)), ('she', (0.002698609776235647, 0.0035007784395124073)), ('in', (0.01724593466931193, 0.0010493904919798248)), ('was', (0.011274095279949884, 0.001654067197176504)), ('have', (0.005163236500563162, 0.0019971285727728785)), ('the', (0.049481544906991, 0.009154264719522947)), ('and', (0.03515709550529561, 0.003556937446919835)), ('to', (0.026136632385615297, 0.001994077042974942)), ('him', (0.004750941149089569, 0.002609431324401042)), ('be', (0.005485431102819282, 0.0007733354141049492)), ('his', (0.012995900132451419, 0.002467063197502821)), ('her', (0.006864612657101059, 0.0043620738164213205)), ('is', (0.004254458319412066, 0.003332876441357822)), ('mr', (0.007356044586395103, 0.004649325526949811)), ('with', (0.009876090036476557, 0.0004201153999028826)), ('had', (0.00720263644585386, 0.0013652091002429945)), ('on', (0.006029177456709314, 0.00047248784626299344)), ('they', (0.0014478696083417692, 0.0023530411374506973)), ('not', (0.004373238055008197, 0.0023920079772321856)), ('me', (0.002141876059150935, 0.0036319724422606008))] \n",
      "\n",
      "prob_of_the_most_common_word --> (0.028191686248284626, 0.0034595859395261225) \n",
      "\n",
      "prob_of_the_most_common_word_x --> (0.03525370385225678, 0.0035190651873532406) \n",
      "\n",
      "prob_of_the --> (0.049481544906991, 0.009154264719522947) \n",
      "\n",
      "prob_of_comma --> (0.09759849180441434, 0.0075208949453729225) \n",
      "\n",
      "avg_dist_consec_comma --> (10.302289686251305, 0.8287185143516964) \n",
      "\n",
      "min_dist_consec_comma --> (1, 0.0) \n",
      "\n",
      "max_dist_consec_comma --> (144.2, 80.42912684124107) \n",
      "\n",
      "avg_dist_consec_MCW --> (35.89075224158865, 3.929700708132867) \n",
      "\n",
      "min_dist_consec_MCW --> (1.4, 0.5163977794943222) \n",
      "\n",
      "max_dist_consec_MCW --> (444.2, 89.27834128287903) \n",
      "\n",
      "avg_dist_consec_MCWx --> (28.615917308011756, 2.810816885319507) \n",
      "\n",
      "min_dist_consec_MCWx --> (1.1, 0.31622776601683794) \n",
      "\n",
      "max_dist_consec_MCWx --> (374.8, 109.23043938796955) \n",
      "\n",
      "avg_dist_consec_the --> (20.77228276867385, 3.4436236386497816) \n",
      "\n",
      "min_dist_consec_the --> (1.5, 0.5270462766947299) \n",
      "\n",
      "max_dist_consec_the --> (316.3, 54.57726429363951) \n",
      "\n",
      "Numero di metriche: 26\n",
      "Lunghezza di prob_distr_of_30: 40\n",
      "Lunghezza di prob_distr_freq_sen: 224\n",
      "0.375002251003293\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# controllo cosa è presente\n",
    "a = cd\n",
    "for key in a.keys():\n",
    "    print(key, \"-->\", a[key], \"\\n\")\n",
    "\n",
    "print(\"Numero di metriche:\", len(a))\n",
    "print(\"Lunghezza di prob_distr_of_30:\", len(a['prob_distr_of_30']))\n",
    "print(\"Lunghezza di prob_distr_freq_sen:\", len(a['prob_distr_freq_sen']))\n",
    "\n",
    "_sum = 0\n",
    "for i in range(len(a['prob_distr_of_30'])):\n",
    "    _sum += a['prob_distr_of_30'][i][1][0]\n",
    "print(_sum)\n",
    "\n",
    "_sum = 0\n",
    "for i in range(len(a['prob_distr_freq_sen'])):\n",
    "    _sum += a['prob_distr_freq_sen'][i][1][0]\n",
    "print(_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento del file in memoria ... caricamento completato\n",
      "Calcolo delle prime metriche, attendere ... calcolo completato\n",
      "Caricamento del file in memoria ... caricamento completato\n",
      "Calcolo di ulteriori metriche, attendere ... calcolo completato\n",
      "Caricamento del file in memoria ... caricamento completato\n",
      "Calcolo delle prime metriche, attendere ... calcolo completato\n",
      "Caricamento del file in memoria ... caricamento completato\n",
      "Calcolo di ulteriori metriche, attendere ... calcolo completato\n",
      "Caricamento del file in memoria ... caricamento completato\n",
      "Calcolo delle prime metriche, attendere ... calcolo completato\n",
      "Caricamento del file in memoria ... caricamento completato\n",
      "Calcolo di ulteriori metriche, attendere ... calcolo completato\n"
     ]
    }
   ],
   "source": [
    "cd2 = generate_metrics(\"analize_files/Charles Dickens___Nicholas Nickleby.txt\")\n",
    "dd2 = generate_metrics(\"analize_files/Daniel Defoe___The Life and Adventures of Robinson Crusoe.txt\")\n",
    "jl2 = generate_metrics(\"analize_files/Jack London___John Barleycorn.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi con probabilità"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supponendo una distribuzione normalizzata, calcolo un valore compreso fra 0 e 1 secondo la funzione di distribuzione di probabilità\n",
    "import numpy as np\n",
    "\n",
    "def gaussian(x, mu, sigma):\n",
    "    if sigma != 0:\n",
    "        return np.exp(-np.power((x - mu)/sigma, 2)/2)\n",
    "    return 1 if x == mu else 0\n",
    "\n",
    "def search_tuple(_list, value):\n",
    "    for tup in _list:\n",
    "        if tup[0] == value:\n",
    "            return tup\n",
    "    return None\n",
    "\n",
    "def verify_author(test_metrics, author_metrics_var):\n",
    "    score = 0\n",
    "    total = 0\n",
    "\n",
    "    for key in test_metrics:\n",
    "        if type(test_metrics[key]) != list:\n",
    "            score += gaussian(test_metrics[key], author_metrics_var[key][0], author_metrics_var[key][1])\n",
    "            total += 1\n",
    "        else:\n",
    "            pass\n",
    "            for tup in test_metrics[key]:\n",
    "                res_search = search_tuple(author_metrics_var[key], tup[0])\n",
    "                \n",
    "                if res_search != None:\n",
    "                    score += gaussian(tup[1], res_search[1][0], res_search[1][1])\n",
    "                    total += 1\n",
    "                \n",
    "                else:\n",
    "                    # penalita' ?????\n",
    "                    total += 1\n",
    "    \n",
    "    return score/total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charles Dickens___Nicholas Nickleby è di Charles Dickens al 58.08376503179796 %\n",
      "Charles Dickens___Nicholas Nickleby è di Daniel Defoe al 51.58526296761317 %\n",
      "Charles Dickens___Nicholas Nickleby è di Jack London al 18.498167188880295 %\n",
      "\n",
      "Daniel Defoe___The Life and Adventures of Robinson Crusoe è di Charles Dickens al 12.529557515276442 %\n",
      "Daniel Defoe___The Life and Adventures of Robinson Crusoe è di Daniel Defoe al 68.93509337529437 %\n",
      "Daniel Defoe___The Life and Adventures of Robinson Crusoe è di Jack London al 11.201268492736407 %\n",
      "\n",
      "Jack London___John Barleycorn è di Charles Dickens al 28.359179079985886 %\n",
      "Jack London___John Barleycorn è di Daniel Defoe al 29.713636504043446 %\n",
      "Jack London___John Barleycorn è di Jack London al 68.48893283725806 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Charles Dickens___Nicholas Nickleby è di Charles Dickens al', verify_author(cd2, cd), '%')\n",
    "print('Charles Dickens___Nicholas Nickleby è di Daniel Defoe al', verify_author(cd2, dd), '%')\n",
    "print('Charles Dickens___Nicholas Nickleby è di Jack London al', verify_author(cd2, jl), '%\\n')\n",
    "\n",
    "print('Daniel Defoe___The Life and Adventures of Robinson Crusoe è di Charles Dickens al', verify_author(dd2, cd), '%')\n",
    "print('Daniel Defoe___The Life and Adventures of Robinson Crusoe è di Daniel Defoe al', verify_author(dd2, dd), '%')\n",
    "print('Daniel Defoe___The Life and Adventures of Robinson Crusoe è di Jack London al', verify_author(dd2, jl), '%\\n')\n",
    "\n",
    "print('Jack London___John Barleycorn è di Charles Dickens al', verify_author(jl2, cd), '%')\n",
    "print('Jack London___John Barleycorn è di Daniel Defoe al', verify_author(jl2, dd), '%')\n",
    "print('Jack London___John Barleycorn è di Jack London al', verify_author(jl2, jl), '%\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
