{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributi sull'intero testo\n",
    "\n",
    "- Dimensione del vocabolario (V)\n",
    "- Lunghezza del testo in numero di parole (T)\n",
    "- Rapporto V/T\n",
    "- Entropia (H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def word_counter(RDD):\n",
    "    '''\n",
    "    Data una RDD, conta quante volte compare ogni parola ritornando anche la dimensione del vocabolario.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD : RDD\n",
    "        RDD del file in input\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (RDD, int)\n",
    "        RDD dell'output del word count e dimensione del vocabolario\n",
    "    '''\n",
    "    \n",
    "    word_counter = (RDD.flatMap(lambda x: x)\n",
    "                    .map(lambda x: (x,1))\n",
    "                    .reduceByKey(lambda a,b: a+b)\n",
    "                    .sortBy(lambda x: -x[1])\n",
    "                   )\n",
    "    \n",
    "    return word_counter, word_counter.count()\n",
    "\n",
    "def text_length_in_words(RDD_word_counter):\n",
    "    '''\n",
    "    Calcola la lunghezza del testo in termini di numero di parole.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_word_counter : RDD\n",
    "        RDD dell'output del word count\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        numero di parole totali presenti nel testo\n",
    "    '''\n",
    "\n",
    "    return (RDD_word_counter.map(lambda x: x[1])\n",
    "            .reduce(lambda a,b: a+b)\n",
    "           )\n",
    "\n",
    "def entropy(RDD_word_counter, text_len):\n",
    "    '''\n",
    "    Calcola l'entropia (numero medio di bit richiesti per rappresentare tutte le parole del testo).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_word_counter : RDD\n",
    "        RDD dell'output del word count\n",
    "    text_len : int\n",
    "        numero di parole totali presenti nel testo\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        valore dell'entropia\n",
    "    '''\n",
    "    \n",
    "    return -(RDD_word_counter.map(lambda x: (x[1]/text_len) * math.log2(x[1]/text_len))\n",
    "             .reduce(lambda a,b: a+b)\n",
    "            )    # l'entropia ha segno negativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributi sulle frasi\n",
    "\n",
    "- Lunghezza massima di una frase (MSL)\n",
    "- Lunghezza media di una frase (ASL)\n",
    "- Lunghezza minima di una frase (mSL)\n",
    "- Distribuzione di probabilità delle lunghezze delle frasi (PDSL)\n",
    "- Probabilità della lunghezza di frase più frequente (pMFSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_lengths(RDD):\n",
    "    '''\n",
    "    Ritorna una lista che contiene le lunghezze (in termini di numero di parole) di tutte le frasi di un testo.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD : RDD\n",
    "        RDD del file in input\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        lunghezze delle frasi\n",
    "    '''\n",
    "    \n",
    "    # OPERAZIONI PRELIMINARI SUL TESTO\n",
    "    text = RDD.flatMap(lambda x: x).reduce(lambda a,b: a + ' ' + b) # METTO TUTTO IL TESTO IN UNA STRINGA UNICA\n",
    "    text = text.replace(\"?\", \".\") # ? TERMINA UNA FRASE\n",
    "    text = text.replace(\"!\", \".\") # ! TERMINA UNA FRASE\n",
    "    text = text.split('. ') # SPLITTO QUANDO TROVO UN CARATTERE CHE TERMINA UNA FRASE (. SEGUITO DA UNO SPAZIO)\n",
    "    \n",
    "    return (sc.parallelize(text)\n",
    "            .map(lambda x: len(x.split(' ')))\n",
    "            .collect()\n",
    "           ) # PER OGNI FRASE TROVATA CONTO LE SUE PAROLE\n",
    "\n",
    "def prob_distr_of_sentence_length(RDD_sen_len):\n",
    "    '''\n",
    "    Ritorna una lista che contiene la distribuzione di probabilità delle lunghezze delle frasi.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_sen_len : RDD\n",
    "        RDD dell'output di sentence_lengths\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        distribuzione di probabilità delle lunghezze delle frasi\n",
    "    '''\n",
    "    \n",
    "    tot = RDD_sen_len.count()\n",
    "\n",
    "    return (RDD_sen_len.map(lambda x: (x,1))\n",
    "            .reduceByKey(lambda a,b: a+b)\n",
    "            .map(lambda x: (x[0], x[1]/tot))\n",
    "            .sortBy(lambda x: -x[1])\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributi sulla probabilità delle parole\n",
    "\n",
    "- Distribuzione di probabilità delle 30 parole più comuni (PkMCW)\n",
    "- Probabilità della parola più comune escludendo 'and' e 'the' (pMCW)\n",
    "- Probabilità della parola più comune escludendo articoli e preposizioni (pMCWx)\n",
    "- Probabilità della parola 'the' (pThe)\n",
    "- Probabilità della virgola (pComma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_distr_of_30_most_common_words(RDD_word_counter, text_len):\n",
    "    '''\n",
    "    Ritorna la distribuzione di probabilità delle 30 parole più comuni.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_word_counter : RDD\n",
    "        RDD dell'output del word count\n",
    "    text_len : int\n",
    "        numero di parole totali presenti nel testo\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    RDD\n",
    "        RDD che contiene la distribuzione di probabilità\n",
    "    '''\n",
    "    \n",
    "    return sc.parallelize(RDD_word_counter.map(lambda x: (x[0], x[1]/text_len)).take(30))\n",
    "\n",
    "def prob_of_the_most_common_word(RDD_word_counter, text_len):\n",
    "    '''\n",
    "    Ritorna la probabilità della parola più comune (escludendo 'and' e 'the').\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_word_counter : RDD\n",
    "        RDD dell'output del word count\n",
    "    text_len : int\n",
    "        numero di parole totali presenti nel testo\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    RDD\n",
    "        RDD che contiene la probabilità della MCW\n",
    "    '''\n",
    "    \n",
    "    return sc.parallelize(prob_distr_of_30_most_common_words(RDD_word_counter, text_len)\n",
    "                          .filter(lambda x: x[0] != \"and\" and x[0] != \"the\")\n",
    "                          .take(1)\n",
    "                         )\n",
    "\n",
    "def prob_of_the_most_common_word_x(RDD_word_counter, text_len):\n",
    "    '''\n",
    "    Ritorna la probabilità della parola più comune (escludendo articoli e preposizioni).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_word_counter : RDD\n",
    "        RDD dell'output del word count\n",
    "    text_len : int\n",
    "        numero di parole totali presenti nel testo\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    RDD\n",
    "        RDD che contiene la probabilità della MCW\n",
    "    '''\n",
    "    \n",
    "    prep_art = open(\"preposizioni_e_articoli.txt\").read().splitlines()\n",
    "    \n",
    "    return sc.parallelize(prob_distr_of_30_most_common_words(RDD_word_counter, text_len)\n",
    "                          .filter(lambda x: x[0] not in prep_art)\n",
    "                          .take(1)\n",
    "                         )\n",
    "\n",
    "def prob_of_The(RDD_word_counter, text_len):\n",
    "    '''\n",
    "    Ritorna la probabilità della parola 'The'.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_word_counter : RDD\n",
    "        RDD dell'output del word count\n",
    "    text_len : int\n",
    "        numero di parole totali presenti nel testo\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    RDD\n",
    "        RDD che contiene la probabilità di 'The'\n",
    "    '''\n",
    "    \n",
    "    return (RDD_word_counter.filter(lambda x: x[0] == \"the\")\n",
    "            .map(lambda x: (x[0], x[1]/text_len))\n",
    "           )\n",
    "\n",
    "def prob_of_comma(RDD_sentences_data, text_len):\n",
    "    '''\n",
    "    Ritorna la probabilità di presenza della virgola.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD_sentences_data : RDD\n",
    "        RDD del file in input\n",
    "    text_len : int\n",
    "        numero di parole totali presenti nel testo\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        probabilità di presenza della virgola\n",
    "    '''\n",
    "    \n",
    "    return (RDD_sentences_data.flatMap(lambda x: x)\n",
    "            .filter(lambda x: \",\" in x)\n",
    "            .count()\n",
    "           ) / text_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributi sulla distanza\n",
    "\n",
    "- Distanza media/minima/massima tra apparenze consecutive della MCW (adMCW, mdMCW, MsMCW)\n",
    "- Distanza media/minima/massima tra apparenze consecutive della MCW escludendo articoli e preposizioni (adMCWx, mdMCWx, MsMCWx)\n",
    "- Distanza media/minima/massima tra apparenze consecutive di 'the' (adThe, mdThe, MsThe)\n",
    "- Distanza media/minima/massima tra apparenze consecutive della virgola (adComma, mdComma, MsComma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_consec_appear(RDD, word):\n",
    "    '''\n",
    "    Ritorna una lista che contiene le distanze tra apparenze consecutive di word.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    RDD : RDD\n",
    "        RDD del file in input\n",
    "    word : str\n",
    "        parola da trattare\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        distanze tra apparenze consecutive di word\n",
    "    '''\n",
    "    \n",
    "    if word == ',':\n",
    "        vect_pos = (RDD.flatMap(lambda x:x)\n",
    "                    .zipWithIndex()\n",
    "                    .filter(lambda x: ',' in x[0])\n",
    "                    .map(lambda x: x[1])\n",
    "                    .collect()\n",
    "                   )\n",
    "    else:\n",
    "        vect_pos = (RDD.flatMap(lambda x:x)\n",
    "                    .zipWithIndex()\n",
    "                    .filter(lambda x: x[0] == word)\n",
    "                    .map(lambda x: x[1])\n",
    "                    .collect()\n",
    "                   )\n",
    "    \n",
    "    vect_dis = []\n",
    "    \n",
    "    for i in range(1, len(vect_pos)):\n",
    "        vect_dis.append(vect_pos[i] - vect_pos[i-1])\n",
    "    \n",
    "    return vect_dis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[2] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_number_some_punctuation_marks(row):\n",
    "    lowercase = row.lower()\n",
    "    lowercase = lowercase.replace(\"--\", \" \")\n",
    "    \n",
    "    res = \"\"\n",
    "    \n",
    "    for char in lowercase:\n",
    "        if not ('0' <= char <= '9' or char == '\"'):\n",
    "            res += char\n",
    "\n",
    "    return res\n",
    "\n",
    "def remove_number_punctuation_marks(row):\n",
    "    lowercase = row.lower()\n",
    "    lowercase = lowercase.replace(\"--\", \" \")\n",
    "    \n",
    "    res = \"\"\n",
    "    \n",
    "    for char in lowercase:\n",
    "        if 'a' <= char <= 'z' or char == ' ' or char == '-' or char == \"'\":\n",
    "            res += char\n",
    "\n",
    "    return res\n",
    "\n",
    "def load_file_without_punctuations_marks(filepath):\n",
    "    # caricamento del dataset\n",
    "    raw_text = sc.textFile(filepath)\n",
    "\n",
    "    # rimuoviamo i numeri e i segni di punteggiatura\n",
    "    \n",
    "    return (raw_text.filter(bool)                    # rimuoviamo le stringhe vuote\n",
    "        .map(remove_number_punctuation_marks)\n",
    "        .map(lambda x : ' '.join(x.split()))        # rimuoviamo diversi spazi bianchi con uno\n",
    "        .map(lambda row : row.split(\" \"))\n",
    "       )\n",
    "\n",
    "def load_file_without_number(filepath):\n",
    "    # caricamento del dataset\n",
    "    raw_text = sc.textFile(filepath)\n",
    "\n",
    "    # rimuoviamo i numeri e i segni di punteggiatura\n",
    "    \n",
    "    return (raw_text.filter(bool)                    # rimuoviamo le stringhe vuote\n",
    "        .map(remove_number_some_punctuation_marks)\n",
    "        .map(lambda x : ' '.join(x.split()))        # rimuoviamo diversi spazi bianchi con uno\n",
    "        .map(lambda row : row.split(\" \"))\n",
    "       )\n",
    "\n",
    "def getCollection(RDD):\n",
    "    return RDD.collect()\n",
    "\n",
    "def getValue(RDD):\n",
    "    return RDD.collect()[0]\n",
    "\n",
    "\n",
    "data = load_file_without_punctuations_marks(\"datasets/Anthony Trollope___The O'Conors of Castle Conor from Tales from all Countries.txt\")\n",
    "data.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V:\t 1558\n",
      "T:\t 7653\n",
      "V/T:\t 0.20358029530902913\n",
      "H:\t 8.605861060321123\n"
     ]
    }
   ],
   "source": [
    "RDD_word_counter, vocabulary_size = word_counter(data)\n",
    "print(\"V:\\t\", vocabulary_size)\n",
    "\n",
    "text_length = text_length_in_words(RDD_word_counter)\n",
    "print(\"T:\\t\", text_length)\n",
    "\n",
    "print(\"V/T:\\t\", vocabulary_size/text_length)\n",
    "\n",
    "entropy_value = entropy(RDD_word_counter, text_length)\n",
    "print(\"H:\\t\", entropy_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[5] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_data = load_file_without_number(\"datasets/Anthony Trollope___The O'Conors of Castle Conor from Tales from all Countries.txt\")\n",
    "sentences_data.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSL:\t 84\n",
      "ASL:\t 14.862135922330097\n",
      "mSL:\t 1\n",
      "PDSL:\t [(7, 0.06407766990291262), (2, 0.05631067961165048), (9, 0.04660194174757282), (10, 0.04660194174757282), (17, 0.04271844660194175), (12, 0.040776699029126215), (8, 0.038834951456310676), (16, 0.038834951456310676), (1, 0.038834951456310676), (3, 0.038834951456310676), (15, 0.038834951456310676), (6, 0.036893203883495145), (11, 0.03495145631067961), (5, 0.03495145631067961), (13, 0.03300970873786408), (4, 0.031067961165048542), (20, 0.02912621359223301), (25, 0.02330097087378641), (22, 0.02330097087378641), (18, 0.021359223300970873), (14, 0.021359223300970873), (19, 0.019417475728155338), (29, 0.019417475728155338), (23, 0.019417475728155338), (21, 0.017475728155339806), (24, 0.015533980582524271), (26, 0.013592233009708738), (28, 0.013592233009708738), (35, 0.011650485436893204), (30, 0.009708737864077669), (31, 0.009708737864077669), (27, 0.007766990291262136), (41, 0.005825242718446602), (33, 0.005825242718446602), (59, 0.005825242718446602), (37, 0.005825242718446602), (38, 0.005825242718446602), (32, 0.003883495145631068), (34, 0.003883495145631068), (46, 0.003883495145631068), (48, 0.001941747572815534), (56, 0.001941747572815534), (40, 0.001941747572815534), (50, 0.001941747572815534), (42, 0.001941747572815534), (43, 0.001941747572815534), (84, 0.001941747572815534), (61, 0.001941747572815534), (54, 0.001941747572815534), (39, 0.001941747572815534), (63, 0.001941747572815534)]\n",
      "pMFSL:\t (7, 0.06407766990291262)\n"
     ]
    }
   ],
   "source": [
    "sen_lengths = sentence_lengths(sentences_data)\n",
    "print(\"MSL:\\t\", max(sen_lengths))\n",
    "print(\"ASL:\\t\", sum(sen_lengths)/len(sen_lengths))\n",
    "print(\"mSL:\\t\", min(sen_lengths))\n",
    "\n",
    "RDD_sen_lengths = sc.parallelize(sen_lengths)\n",
    "\n",
    "prob_distr_freq_sen = prob_distr_of_sentence_length(RDD_sen_lengths)\n",
    "print(\"PDSL:\\t\", getCollection(prob_distr_freq_sen))\n",
    "print(\"pMFSL:\\t\", getValue(prob_distr_freq_sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PkMCW:\t [('the', 0.04494969293087678), ('i', 0.036717627074349925), ('and', 0.033320266562132494), ('to', 0.023650855873513656), ('of', 0.021298837057363126), ('a', 0.019730824513262774), ('my', 0.01620279628903698), ('that', 0.016072128577028617), ('in', 0.015941460865020254), ('was', 0.01528812230497844), ('said', 0.012152097216777734), ('as', 0.011106755520710831), ('he', 0.011106755520710831), ('at', 0.009930746112635568), ('but', 0.009669410688618842), ('you', 0.009277407552593753), ('for', 0.009146739840585392), ('me', 0.00862406899255194), ('it', 0.00862406899255194), ('had', 0.007840062720501764), ('with', 0.00718672416045995), ('not', 0.006533385600418136), (\"o'conor\", 0.006272050176401411), ('all', 0.006141382464393048), ('his', 0.005880047040376323), ('were', 0.00574937932836796), ('on', 0.005618711616359597), ('so', 0.004965373056317784), ('there', 0.004704037632301058), ('we', 0.004704037632301058)]\n",
      "pMCW:\t ('i', 0.036717627074349925)\n",
      "pMCWx:\t ('i', 0.036717627074349925)\n",
      "pThe:\t ('the', 0.04494969293087678)\n",
      "pComma:\t 0.06768587482033189\n"
     ]
    }
   ],
   "source": [
    "RDD_prob_distr_of_30 = prob_distr_of_30_most_common_words(RDD_word_counter, text_length)\n",
    "print(\"PkMCW:\\t\", getCollection(RDD_prob_distr_of_30))\n",
    "\n",
    "RDD_prob_the_most_common_word_1 = prob_of_the_most_common_word(RDD_word_counter, text_length)\n",
    "print(\"pMCW:\\t\", getValue(RDD_prob_the_most_common_word_1))\n",
    "\n",
    "RDD_prob_the_most_common_word_2 = prob_of_the_most_common_word_x(RDD_word_counter, text_length)\n",
    "print(\"pMCWx:\\t\", getValue(RDD_prob_the_most_common_word_2))\n",
    "\n",
    "RDD_prob_the = prob_of_The(RDD_word_counter, text_length)\n",
    "print(\"pThe:\\t\", getValue(RDD_prob_the))\n",
    "\n",
    "p_comma = prob_of_comma(sentences_data, text_length)\n",
    "print(\"pComma:\\t\", p_comma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adMCW:\t 27.15357142857143\n",
      "mdMCW:\t 2\n",
      "MdMCW:\t 177\n",
      "adMCWx:\t 27.15357142857143\n",
      "mdMCWx:\t 2\n",
      "MdMCWx:\t 177\n",
      "adThe:\t 22.244897959183675\n",
      "mdThe:\t 2\n",
      "MdThe:\t 115\n",
      "adComma: 14.713733075435202\n",
      "mdComma: 1\n",
      "MdComma: 92\n"
     ]
    }
   ],
   "source": [
    "MCW = getValue(RDD_prob_the_most_common_word_1)[0]\n",
    "dist_consec_MCW = distance_consec_appear(data, MCW)\n",
    "print(\"adMCW:\\t\", sum(dist_consec_MCW)/len(dist_consec_MCW))\n",
    "print(\"mdMCW:\\t\", min(dist_consec_MCW))\n",
    "print(\"MdMCW:\\t\", max(dist_consec_MCW))\n",
    "\n",
    "MCWx = getValue(RDD_prob_the_most_common_word_1)[0]\n",
    "dist_consec_MCWx = distance_consec_appear(data, MCWx)\n",
    "print(\"adMCWx:\\t\", sum(dist_consec_MCWx)/len(dist_consec_MCWx))\n",
    "print(\"mdMCWx:\\t\", min(dist_consec_MCWx))\n",
    "print(\"MdMCWx:\\t\", max(dist_consec_MCWx))\n",
    "\n",
    "dist_consec_the = distance_consec_appear(data, 'the')\n",
    "print(\"adThe:\\t\", sum(dist_consec_the)/len(dist_consec_the))\n",
    "print(\"mdThe:\\t\", min(dist_consec_the))\n",
    "print(\"MdThe:\\t\", max(dist_consec_the))\n",
    "\n",
    "dist_consec_comma = distance_consec_appear(sentences_data, ',')\n",
    "print(\"adComma:\", sum(dist_consec_comma)/len(dist_consec_comma))\n",
    "print(\"mdComma:\", min(dist_consec_comma))\n",
    "print(\"MdComma:\", max(dist_consec_comma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
