{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definizione delle funzioni di supporto\n",
    "'''\n",
    "\n",
    "def remove_number_some_punctuation_marks(row):\n",
    "    '''\n",
    "    remove_number:   rimuove i caratteri numerici e il carattere '\"' dalla stringa e la trasforma in lower-case\n",
    "    '''\n",
    "    lowercase = row.lower()\n",
    "    lowercase = lowercase.replace(\"--\", \" \")\n",
    "    res = \"\"\n",
    "    \n",
    "    for char in lowercase:\n",
    "        if not ('0' <= char <= '9' or char == '\"'):\n",
    "            res += char\n",
    "\n",
    "    return res\n",
    "\n",
    "def remove_number_punctuation_marks(row):\n",
    "    '''\n",
    "    remove_number:   rimuove i caratteri numerici dalla stringa e i segni di punteggiatura \n",
    "                     e la trasforma in lower-case\n",
    "    '''\n",
    "    \n",
    "    lowercase = row.lower()\n",
    "    lowercase = lowercase.replace(\"--\", \" \")\n",
    "    res = \"\"\n",
    "    \n",
    "    for char in lowercase:\n",
    "        if 'a' <= char <= 'z' or char == ' ' or char == '-' or char == \"'\":\n",
    "            res += char\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Definizione delle funzioni che calcolano le metriche per la Authorship Attribution\n",
    "'''\n",
    "\n",
    "def word_counter(RDD):\n",
    "    '''\n",
    "    word_counter:   è la funzione che dato un RDD conta il numero di volte che compare una parola.\n",
    "                    Inoltre per risparmiare operazioni ritorna anche l'ATTRIBUTO VOCABULARY_SIZE\n",
    "    '''\n",
    "    word_counter = (RDD.flatMap(lambda x: x)\n",
    "                .map(lambda x: (x,1))\n",
    "                .reduceByKey(lambda a,b: a+b)\n",
    "                .sortBy(lambda x: -x[1])\n",
    "               )\n",
    "    return word_counter.collect(), len(word_counter.collect())\n",
    "\n",
    "def text_length_in_words(word_count):\n",
    "    '''\n",
    "    text_length_in_words:   calcola il numero di parole del testo usando word_counter\n",
    "    '''\n",
    "    s = 0\n",
    "    for couple in word_count:\n",
    "        s += couple[1]\n",
    "    return s\n",
    "\n",
    "def ratio_V_T(voc_size, text_len):\n",
    "    '''\n",
    "    ratio_V_T:   calcola il rapporto fra la dimensione del vocabolario e il numero totale di parole\n",
    "                 nel testo\n",
    "    '''\n",
    "    return voc_size / text_len\n",
    "\n",
    "def hentropy(word_count,text_len):\n",
    "    import math\n",
    "    '''\n",
    "    hentropy:   funzione che calcola l'entropia usando l'Entropia di Gibbs. L'unica differenza\n",
    "                è la mancanza della costante di Boltzmann\n",
    "    '''\n",
    "    s = 0\n",
    "    \n",
    "    for couple in word_count:\n",
    "        s += (couple[1]/text_len) * math.log2(couple[1]/text_len)\n",
    "    \n",
    "    return -s\n",
    "\n",
    "def maximum_sentence_length(sentence_collection):\n",
    "    '''\n",
    "    maximum_sentence_length:   funzione che calcola la lunghezza (in numero di parole) della frase\n",
    "                               più lunga\n",
    "    '''\n",
    "    _max = float(\"-inf\")\n",
    "    \n",
    "    for sentence in sentence_collection:\n",
    "        if len(sentence) > _max:\n",
    "            _max = len(sentence)\n",
    "    return _max\n",
    "\n",
    "def minimum_sentence_length(sentence_collection):\n",
    "    '''\n",
    "    minimum_sentence_length:   funzione che calcola la lunghezza (in numero di parole) della frase\n",
    "                               più corta\n",
    "    '''\n",
    "    _min = float(\"inf\")\n",
    "    \n",
    "    for sentence in sentence_collection:\n",
    "        if len(sentence) < _min and len(sentence) > 0:\n",
    "            _min = len(sentence)\n",
    "    return _min\n",
    "\n",
    "def average_sentence_length(sentence_collection):\n",
    "    '''\n",
    "    average_sentence_length:   funzione che calcola la lunghezza media(in numero di parole)\n",
    "                               delle frasi del testo\n",
    "    '''\n",
    "    _sum = 0\n",
    "    \n",
    "    for sentence in sentence_collection:\n",
    "        _sum += len(sentence)\n",
    "    return _sum / len(sentence_collection)\n",
    "\n",
    "\n",
    "def prob_of_the_most_freq_sentence_len(sentence_collection):\n",
    "    '''\n",
    "    prob_of_the_most_freq_sentence_len:   funzione che calcola la probabilità\n",
    "            della lunghezza della frase più frequente\n",
    "    '''\n",
    "    \n",
    "    # coppia (lunghezza_frase, numero_frasi_con_\"lunghezza_frase\")\n",
    "    d = dict()\n",
    "    \n",
    "    for sentence in sentence_collection:\n",
    "        try:\n",
    "            d[len(sentence)] += 1\n",
    "        except:\n",
    "            d[len(sentence)] = 1\n",
    "    \n",
    "    _max_freq = 0\n",
    "    \n",
    "    for key in d:\n",
    "        if _max_freq < d[key]:\n",
    "            _max_freq = d[key]\n",
    "    \n",
    "    return _max_freq / len(sentence_collection)\n",
    "\n",
    "def prob_distr_of_30_most_common_words(word_count):\n",
    "    '''\n",
    "    prob_distr_of_30_most_common_words: funzione che ritorna una lista di probabilità\n",
    "                                        delle 30 parole di uso più comune\n",
    "    '''    \n",
    "    res = []\n",
    "    _sum = 0\n",
    "    \n",
    "    for couple in word_count:\n",
    "        _sum += couple[1]\n",
    "    \n",
    "    # word_count è ordinato\n",
    "    for i in range(0, 30):\n",
    "        res.append((word_count[i][0], word_count[i][1] / _sum))\n",
    "        \n",
    "    return res\n",
    "\n",
    "def prob_distr_of_30_most_common_words_except_art_prep(word_count, art_prep):\n",
    "    '''\n",
    "    prob_distr_of_30_most_common_words_except_art_prep: funzione che ritorna una lista di probabilità\n",
    "                                                        delle 30 parole di uso più comune escludendo articoli\n",
    "                                                        e preposizioni\n",
    "    '''\n",
    "    \n",
    "    res = []\n",
    "    _sum = 0\n",
    "    \n",
    "    for couple in word_count:\n",
    "        if couple[0] not in art_prep:\n",
    "            _sum += couple[1]\n",
    "    \n",
    "    # word_count è ordinato\n",
    "    i = 0\n",
    "    counter = 0\n",
    "    \n",
    "    for couple in word_count:\n",
    "        if couple[0] not in art_prep:\n",
    "            res.append((word_count[i][0], word_count[i][1] / _sum))\n",
    "            counter += 1\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "        if counter == 29:\n",
    "            break\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def prob_distr_of_sentence_length(sentence_collection):\n",
    "    '''\n",
    "    prob_distr_of_sentence_length:   funzione che calcola la distribuzione di probabilità\n",
    "                                     della lunghezza della frasi\n",
    "    '''    \n",
    "    d = dict()\n",
    "    \n",
    "    for sentence in sentence_collection:\n",
    "        try:\n",
    "            d[len(sentence)] += 1\n",
    "        except:\n",
    "            d[len(sentence)] = 1\n",
    "        \n",
    "    \n",
    "    for key in d:\n",
    "        d[key] /= len(sentence_collection)\n",
    "    \n",
    "    return d\n",
    "\n",
    "\n",
    "def prob_of_The(word_count):\n",
    "    '''\n",
    "    prob_of_The: funzione che ritorna la probabilità di \"the\" \n",
    "    '''\n",
    "    _sum = 0\n",
    "    value = 0\n",
    "    for couple in word_count:\n",
    "        if couple[0] == \"the\":\n",
    "            value = couple[1]\n",
    "        _sum += couple[1]\n",
    "    \n",
    "    return value / _sum\n",
    "\n",
    "def prob_of_comma(sentences_collection):\n",
    "    '''\n",
    "    prob_of_The: funzione che ritorna la probabilità che capiti una virgola\n",
    "    '''\n",
    "    \n",
    "    _sum = 0\n",
    "    value = 0\n",
    "    for sentence in sentences_collection:\n",
    "        for word in sentence:         \n",
    "            if \",\" in word:\n",
    "                value += 1\n",
    "            _sum += 1\n",
    "\n",
    "    return value / _sum\n",
    "\n",
    "def prob_of_the_most_common_word(word_count):\n",
    "    '''\n",
    "    prob_of_the_most_common_word: funzione che ritorna la probabilità della parola più\n",
    "                                  comune escudendo \"the\" e \"and\"\n",
    "    '''\n",
    "    # distribuzione di probabilità\n",
    "    pd = prob_distr_of_30_most_common_words(word_count)\n",
    "    \n",
    "    for couple in pd:\n",
    "        if couple[0] != \"and\" and couple[0] != \"the\":\n",
    "            return couple\n",
    "\n",
    "def prob_of_the_most_common_word_except_art_prep(word_count, art_prep):\n",
    "    '''\n",
    "    prob_of_the_most_common_word_except_art_prep: funzione che ritorna la probabilità della parola più\n",
    "                                                  comune escudendo articoli e preposizioni\n",
    "    '''\n",
    "    \n",
    "    # distribuzione di probabilità\n",
    "    pd = prob_distr_of_30_most_common_words_except_art_prep(word_count, art_prep)\n",
    "    \n",
    "    return pd[0]\n",
    "\n",
    "def MCW_except_the(word_count):\n",
    "    '''\n",
    "    MCW_except_the: funzione che ritorna la parola più comune a eccezione di \"the\"\n",
    "    '''\n",
    "    for couple in word_count:\n",
    "        if couple[0] != \"the\":\n",
    "            return couple[0]\n",
    "\n",
    "def MCW_except_art_prep(word_count, art_prep):\n",
    "    '''\n",
    "    MCW_except_the: funzione che ritorna la parola più comune a eccezione di \"the\"\n",
    "    '''\n",
    "    for couple in word_count:\n",
    "        if couple[0] not in art_prep:\n",
    "            return couple[0]\n",
    "        \n",
    "def avg_distance_consec_appear_MCW(data):\n",
    "    '''\n",
    "    avg_distance_consec_appear_MCW: funzione che calcola la distanza media di due parole MCW consecutive.\n",
    "                                    MCW indica la parola di uso più comune escludendo la parola \"the\"\n",
    "    '''\n",
    "    MCW = MCW_except_the(word_counter(data)[0])\n",
    "    \n",
    "    ds = []\n",
    "    ds.append(1) # inizializziamo la lista delle distanze\n",
    "    \n",
    "    for line in data.collect():\n",
    "        for word in line:\n",
    "            if MCW == word:\n",
    "                ds.append(1)\n",
    "            else:\n",
    "                ds[len(ds) - 1] += 1\n",
    "    _avg = 0\n",
    "    \n",
    "    for d in ds:\n",
    "        _avg += d\n",
    "    \n",
    "    return _avg / len(ds)\n",
    "\n",
    "def min_distance_consec_appear_MCW(data):\n",
    "    MCW = MCW_except_the(word_counter(data)[0])\n",
    "    \n",
    "    ds = []\n",
    "    ds.append(1) # inizializziamo la lista delle distanze\n",
    "    \n",
    "    for line in data.collect():\n",
    "        for word in line:\n",
    "            if MCW == word:\n",
    "                ds.append(1)\n",
    "            else:\n",
    "                ds[len(ds) - 1] += 1\n",
    "\n",
    "    return min(ds)\n",
    "\n",
    "def max_distance_consec_appear_MCW(data):\n",
    "    MCW = MCW_except_the(word_counter(data)[0])\n",
    "    \n",
    "    ds = []\n",
    "    ds.append(1) # inizializziamo la lista delle distanze\n",
    "    \n",
    "    for line in data.collect():\n",
    "        for word in line:\n",
    "            if MCW == word:\n",
    "                ds.append(1)\n",
    "            else:\n",
    "                ds[len(ds) - 1] += 1\n",
    "\n",
    "    return max(ds)\n",
    "\n",
    "def avg_distance_consec_appear_MCW_except_art_prep(data, art_prep):\n",
    "    '''\n",
    "    avg_distance_consec_appear_MCW_except_art_prep: funzione che calcola la distanza media di due parole MCW consecutive.\n",
    "                                                    MCW indica la parola di uso più comune escludendo articoli e preposizioni\n",
    "    '''\n",
    "    MCW = MCW_except_art_prep(word_counter(data)[0], art_prep)\n",
    "    \n",
    "    ds = []\n",
    "    ds.append(1) # inizializziamo la lista delle distanze\n",
    "    \n",
    "    for line in data.collect():\n",
    "        for word in line:\n",
    "            if MCW == word:\n",
    "                ds.append(1)\n",
    "            else:\n",
    "                ds[len(ds) - 1] += 1\n",
    "    _avg = 0\n",
    "    \n",
    "    for d in ds:\n",
    "        _avg += d\n",
    "    \n",
    "    return _avg / len(ds)\n",
    "\n",
    "def min_distance_consec_appear_MCW_except_art_prep(data, art_prep):\n",
    "    \n",
    "    MCW = MCW_except_art_prep(word_counter(data)[0], art_prep)\n",
    "    \n",
    "    ds = []\n",
    "    ds.append(1) # inizializziamo la lista delle distanze\n",
    "    \n",
    "    for line in data.collect():\n",
    "        for word in line:\n",
    "            if MCW == word:\n",
    "                ds.append(1)\n",
    "            else:\n",
    "                ds[len(ds) - 1] += 1\n",
    "\n",
    "    return min(ds)\n",
    "\n",
    "def max_distance_consec_appear_MCW_except_art_prep(data, art_prep):\n",
    "    MCW = MCW_except_art_prep(word_counter(data)[0], art_prep)\n",
    "    \n",
    "    ds = []\n",
    "    ds.append(1) # inizializziamo la lista delle distanze\n",
    "    \n",
    "    for line in data.collect():\n",
    "        for word in line:\n",
    "            if MCW == word:\n",
    "                ds.append(1)\n",
    "            else:\n",
    "                ds[len(ds) - 1] += 1\n",
    "\n",
    "    return max(ds)\n",
    "\n",
    "\n",
    "def avg_distance_consec_appear_of_The(data):\n",
    "    '''\n",
    "    avg_distance_consec_appear_MCW: funzione che calcola la distanza media di due parole \"the\" consecutive.\n",
    "                                    MCW indica la parola di uso più comune escludendo la parola \"the\"\n",
    "    '''    \n",
    "    ds = []\n",
    "    ds.append(1) # inizializziamo la lista delle distanze\n",
    "    \n",
    "    for line in data.collect():\n",
    "        for word in line:\n",
    "            if \"the\" == word:\n",
    "                ds.append(1)\n",
    "            else:\n",
    "                ds[len(ds) - 1] += 1\n",
    "    _avg = 0\n",
    "    \n",
    "    for d in ds:\n",
    "        _avg += d\n",
    "    \n",
    "    return _avg / len(ds)\n",
    "\n",
    "def min_distance_consec_appear_of_The(data):\n",
    "    '''\n",
    "    min_distance_consec_appear_of_The: funzione che calcola la distanza minima di due parole \"the\" consecutive.\n",
    "                                       MCW indica la parola di uso più comune escludendo la parola \"the\"\n",
    "    ''' \n",
    "    ds = []\n",
    "    ds.append(1) # inizializziamo la lista delle distanze\n",
    "    \n",
    "    for line in data.collect():\n",
    "        for word in line:\n",
    "            if \"the\" == word:\n",
    "                ds.append(1)\n",
    "            else:\n",
    "                ds[len(ds) - 1] += 1\n",
    "\n",
    "    return min(ds)\n",
    "\n",
    "def max_distance_consec_appear_of_The(data):\n",
    "    '''\n",
    "    max_distance_consec_appear_of_The: funzione che calcola la distanza massima di due parole \"the\" consecutive.\n",
    "                                       MCW indica la parola di uso più comune escludendo la parola \"the\"\n",
    "    ''' \n",
    "    ds = []\n",
    "    ds.append(1) # inizializziamo la lista delle distanze\n",
    "    \n",
    "    for line in data.collect():\n",
    "        for word in line:\n",
    "            if \"the\" == word:\n",
    "                ds.append(1)\n",
    "            else:\n",
    "                ds[len(ds) - 1] += 1\n",
    "\n",
    "    return max(ds)\n",
    "\n",
    "\n",
    "def avg_distance_consec_appear_of_comma(senteces_collection):\n",
    "    '''\n",
    "    avg_distance_consec_appear_of_comma: funzione che calcola la distanza media di due consecutive virgole.\n",
    "    '''    \n",
    "    ds = []\n",
    "    ds.append(1) # inizializziamo la lista delle distanze\n",
    "    \n",
    "    for line in senteces_collection:\n",
    "        for word in line:\n",
    "            if \",\" in word:\n",
    "                ds.append(1)\n",
    "            else:\n",
    "                ds[len(ds) - 1] += 1\n",
    "    _avg = 0\n",
    "    \n",
    "    for d in ds:\n",
    "        _avg += d\n",
    "    \n",
    "    return _avg / len(ds)\n",
    "\n",
    "def min_distance_consec_appear_of_comma(senteces_collection):\n",
    "    '''\n",
    "    min_distance_consec_appear_of_comma: funzione che calcola la distanza minima di due consecutive virgole.\n",
    "    ''' \n",
    "    ds = []\n",
    "    ds.append(1) # inizializziamo la lista delle distanze\n",
    "    \n",
    "    for sentence in senteces_collection:\n",
    "        for word in sentence:\n",
    "            if \",\" in word:\n",
    "                ds.append(1)\n",
    "            else:\n",
    "                ds[len(ds) - 1] += 1\n",
    "\n",
    "    return min(ds)\n",
    "\n",
    "def max_distance_consec_appear_of_comma(senteces_collection):\n",
    "    '''\n",
    "    max_distance_consec_appear_of_comma: funzione che calcola la distanza massima di due consecutive virgole.\n",
    "    ''' \n",
    "    ds = []\n",
    "    ds.append(1) # inizializziamo la lista delle distanze\n",
    "    \n",
    "    for sentence in senteces_collection:\n",
    "        for word in sentence:\n",
    "            if \",\" in word:\n",
    "                ds.append(1)\n",
    "            else:\n",
    "                ds[len(ds) - 1] += 1\n",
    "\n",
    "    return max(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[184] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CARICAMENTO PREPOSIZIONI E ARTICOLI\n",
    "\n",
    "raw_art_prep = sc.textFile(\"preposizioni_e_articoli.txt\")\n",
    "\n",
    "# RIMUOVIAMO NUMERI + SEGNI DI PUNTEGGIATURA\n",
    "art_prep = raw_art_prep.filter(bool)\n",
    "\n",
    "# POSIAMO I DATI NELLA CACHE\n",
    "art_prep.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[187] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CARICAMENTO DATASET\n",
    "\n",
    "rawData = sc.textFile(\"datasets/Anthony Trollope___The O'Conors of Castle Conor from Tales from all Countries.txt\")\n",
    "\n",
    "# RIMUOVIAMO NUMERI + SEGNI DI PUNTEGGIATURA\n",
    "data = (rawData.filter(bool)                    # rimuoviamo le stringhe vuote\n",
    "        .map(remove_number_punctuation_marks)\n",
    "        .map(lambda x : ' '.join(x.split()))    # rimuoviamo diversi spazi bianchi con uno\n",
    "        .map(lambda row : row.split(\" \"))\n",
    "       )\n",
    "\n",
    "# POSIAMO I DATI NELLA CACHE\n",
    "data.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_counter, e ATTRIBUTO vocabulary_size\n",
    "word_count, voc_size = word_counter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7600\n"
     ]
    }
   ],
   "source": [
    "# SOMMA LE FREQUENZE DENTRO word_count PER TROVARE L'ATTRIBUTO text_length_in_words\n",
    "text_len = text_length_in_words(word_count)\n",
    "print(text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21039473684210527"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ATTRIBUTO definito rapporto vocabulary_size / text_length_in_words\n",
    "ratio_V_T(voc_size, text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.639377320109679"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ENTROPIA misura formalmente la quantità di disordine\n",
    "hentropy(word_count,text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "1\n",
      "14.833333333333334\n"
     ]
    }
   ],
   "source": [
    "# linee del file in input\n",
    "lines = (rawData.filter(bool)\n",
    "            .map(remove_number_some_punctuation_marks)\n",
    "            .map(lambda x : ' '.join(x.split()))\n",
    "            )\n",
    "\n",
    "# METTO TUTTO IL TESTO IN UNA STRINGA UNICA\n",
    "text = ''\n",
    "for s in lines.collect():\n",
    "    text += s + ' '\n",
    "\n",
    "text = text.replace(\"?\", \".\")\n",
    "text = text.replace(\"!\", \".\")\n",
    "\n",
    "# LISTA DI STRINGHE. ESSE SONO FRASI\n",
    "sentences = text.split(\".\")\n",
    "\n",
    "# LISTA DI LISTE CHE CONTENGONO LE PAROLE DI UNA FRASE\n",
    "senteces_collection = sc.parallelize(sentences).map(lambda x: x.split()).collect()\n",
    "\n",
    "#print(senteces_collection)\n",
    "\n",
    "# 81\n",
    "print(maximum_sentence_length(senteces_collection))\n",
    "# 1\n",
    "print(minimum_sentence_length(senteces_collection))\n",
    "# 17.473563218390805\n",
    "print(average_sentence_length(senteces_collection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06395348837209303"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_of_the_most_freq_sentence_len(senteces_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0.04513157894736842),\n",
       " ('i', 0.03605263157894737),\n",
       " ('and', 0.0325),\n",
       " ('to', 0.02368421052631579),\n",
       " ('of', 0.02131578947368421),\n",
       " ('a', 0.019736842105263157),\n",
       " ('my', 0.01631578947368421),\n",
       " ('that', 0.016052631578947367),\n",
       " ('in', 0.015921052631578947),\n",
       " ('was', 0.015394736842105263),\n",
       " ('said', 0.012236842105263157),\n",
       " ('he', 0.01118421052631579),\n",
       " ('as', 0.011052631578947368),\n",
       " ('but', 0.009736842105263158),\n",
       " ('at', 0.009605263157894737),\n",
       " ('you', 0.008947368421052631),\n",
       " ('for', 0.008815789473684211),\n",
       " ('it', 0.008552631578947369),\n",
       " ('me', 0.008421052631578947),\n",
       " ('had', 0.007894736842105263),\n",
       " ('with', 0.007236842105263158),\n",
       " ('not', 0.00631578947368421),\n",
       " ('all', 0.0061842105263157894),\n",
       " (\"o'conor\", 0.0061842105263157894),\n",
       " ('his', 0.005789473684210527),\n",
       " ('were', 0.005789473684210527),\n",
       " ('on', 0.005394736842105263),\n",
       " ('so', 0.005),\n",
       " ('there', 0.004736842105263158),\n",
       " ('we', 0.004736842105263158)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_distr_of_30_most_common_words(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', 0.03605263157894737)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_of_the_most_common_word(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_distance_consec_appear_MCW(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_distance_consec_appear_MCW(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "176"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance_consec_appear_MCW(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.09593023255814"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_distance_consec_appear_of_The(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_distance_consec_appear_of_The(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance_consec_appear_of_The(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04513157894736842"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_of_The(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.7495183044316"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_distance_consec_appear_of_comma(senteces_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_distance_consec_appear_of_comma(senteces_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance_consec_appear_of_comma(senteces_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06767703161745492"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_of_comma(senteces_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 0.06395348837209303,\n",
       " 35: 0.011627906976744186,\n",
       " 20: 0.029069767441860465,\n",
       " 12: 0.040697674418604654,\n",
       " 17: 0.04263565891472868,\n",
       " 26: 0.013565891472868217,\n",
       " 41: 0.005813953488372093,\n",
       " 23: 0.01937984496124031,\n",
       " 6: 0.03682170542635659,\n",
       " 18: 0.02131782945736434,\n",
       " 61: 0.001937984496124031,\n",
       " 2: 0.0562015503875969,\n",
       " 28: 0.013565891472868217,\n",
       " 38: 0.005813953488372093,\n",
       " 25: 0.023255813953488372,\n",
       " 39: 0.001937984496124031,\n",
       " 59: 0.005813953488372093,\n",
       " 54: 0.001937984496124031,\n",
       " 30: 0.009689922480620155,\n",
       " 15: 0.03875968992248062,\n",
       " 48: 0.001937984496124031,\n",
       " 10: 0.046511627906976744,\n",
       " 8: 0.03875968992248062,\n",
       " 24: 0.015503875968992248,\n",
       " 14: 0.02131782945736434,\n",
       " 4: 0.031007751937984496,\n",
       " 1: 0.03875968992248062,\n",
       " 22: 0.023255813953488372,\n",
       " 3: 0.03875968992248062,\n",
       " 5: 0.03488372093023256,\n",
       " 9: 0.046511627906976744,\n",
       " 11: 0.03488372093023256,\n",
       " 29: 0.01937984496124031,\n",
       " 27: 0.007751937984496124,\n",
       " 63: 0.001937984496124031,\n",
       " 32: 0.003875968992248062,\n",
       " 46: 0.003875968992248062,\n",
       " 16: 0.03875968992248062,\n",
       " 13: 0.03294573643410853,\n",
       " 37: 0.005813953488372093,\n",
       " 34: 0.003875968992248062,\n",
       " 19: 0.01937984496124031,\n",
       " 84: 0.001937984496124031,\n",
       " 21: 0.01744186046511628,\n",
       " 56: 0.001937984496124031,\n",
       " 43: 0.001937984496124031,\n",
       " 33: 0.005813953488372093,\n",
       " 31: 0.009689922480620155,\n",
       " 50: 0.001937984496124031,\n",
       " 40: 0.001937984496124031,\n",
       " 42: 0.001937984496124031,\n",
       " 0: 0.001937984496124031}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_distr_of_sentence_length(senteces_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.141843971631207"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_distance_consec_appear_MCW_except_art_prep(data, art_prep.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_distance_consec_appear_MCW_except_art_prep(data, art_prep.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_distance_consec_appear_MCW_except_art_prep(data, art_prep.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 0.04608139926000673),\n",
       " ('and', 0.04154053144971409),\n",
       " ('my', 0.020854355869492094),\n",
       " ('that', 0.020517995290951902),\n",
       " ('was', 0.019677093844601413),\n",
       " ('said', 0.01564076690211907),\n",
       " ('he', 0.014295324587958291),\n",
       " ('you', 0.011436259670366633),\n",
       " ('it', 0.01093171880255634),\n",
       " ('me', 0.010763538513286243),\n",
       " ('had', 0.010090817356205853),\n",
       " ('not', 0.008072653884964682),\n",
       " ('all', 0.007904473595694584),\n",
       " (\"o'conor\", 0.007904473595694584),\n",
       " ('his', 0.007399932727884292),\n",
       " ('were', 0.007399932727884292),\n",
       " ('so', 0.006390850992263707),\n",
       " ('there', 0.006054490413723511),\n",
       " ('we', 0.006054490413723511),\n",
       " ('mr', 0.005886310124453414),\n",
       " ('this', 0.005886310124453414),\n",
       " ('larry', 0.005886310124453414),\n",
       " ('which', 0.005886310124453414),\n",
       " ('be', 0.005886310124453414),\n",
       " ('is', 0.005718129835183316),\n",
       " ('then', 0.0053817692566431215),\n",
       " ('have', 0.005213588967373024),\n",
       " ('jack', 0.005213588967373024),\n",
       " ('they', 0.004877228388832829)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_distr_of_30_most_common_words_except_art_prep(word_count, art_prep.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', 0.04608139926000673)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_of_the_most_common_word_except_art_prep(word_count, art_prep.collect())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
